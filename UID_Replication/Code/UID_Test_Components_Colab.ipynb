{
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.0"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jo9bhAPV8AaT"
      },
      "source": [
        "# UID Test Components - For Colab\n",
        "\n",
        "Test each function individually."
      ],
      "id": "jo9bhAPV8AaT"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0JWDuYv38AaV"
      },
      "source": [
        "# SETUP\n",
        "\n",
        "import os\n",
        "import math\n",
        "import random\n",
        "from collections import defaultdict, Counter\n",
        "from itertools import permutations\n",
        "import numpy as np\n",
        "from scipy import stats\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import KFold\n",
        "\n",
        "random.seed(42)\n",
        "np.random.seed(42)"
      ],
      "outputs": [],
      "id": "0JWDuYv38AaV"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wG0ep6CT8AaX",
        "outputId": "e34dc5e7-bb6f-42e8-d6f2-ddcb4ec7d880"
      },
      "source": [
        "# TEST 1: Token and Sentence classes\n",
        "\n",
        "class Token:\n",
        "    def __init__(self, id, form, lemma, upos, xpos, feats, head, deprel, deps, misc):\n",
        "        self.id = id\n",
        "        self.form = form\n",
        "        self.lemma = lemma\n",
        "        self.upos = upos\n",
        "        self.xpos = xpos\n",
        "        self.feats = feats\n",
        "        self.head = head\n",
        "        self.deprel = deprel\n",
        "        self.deps = deps\n",
        "        self.misc = misc\n",
        "\n",
        "class Sentence:\n",
        "    def __init__(self, sent_id, text, tokens):\n",
        "        self.sent_id = sent_id\n",
        "        self.text = text\n",
        "        self.tokens = tokens\n",
        "\n",
        "    def get_root(self):\n",
        "        for t in self.tokens:\n",
        "            if t.head == 0:\n",
        "                return t\n",
        "        return None\n",
        "\n",
        "    def get_word_sequence(self):\n",
        "        return [t.form for t in sorted(self.tokens, key=lambda x: x.id)]\n",
        "\n",
        "# Test\n",
        "tok1 = Token(1, 'राम', 'राम', 'PROPN', 'NNP', {}, 2, 'nsubj', '_', '_')\n",
        "tok2 = Token(2, 'खाता', 'खा', 'VERB', 'VM', {}, 0, 'root', '_', '_')\n",
        "sent = Sentence('s1', 'राम खाता है', [tok1, tok2])\n",
        "\n",
        "print(f\"Root: {sent.get_root().form}\")\n",
        "print(f\"Words: {sent.get_word_sequence()}\")\n",
        "print('Test 1 passed!')"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Root: खाता\n",
            "Words: ['राम', 'खाता']\n",
            "Test 1 passed!\n"
          ]
        }
      ],
      "id": "wG0ep6CT8AaX"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lBGJfOcN8AaY",
        "outputId": "fe5ccde3-a95c-43d9-c727-e96ae7bf0bff"
      },
      "source": [
        "# TEST 2: CoNLL-U Parser\n",
        "\n",
        "def parse_feats(feats_str):\n",
        "    feats = {}\n",
        "    if feats_str and feats_str != '_':\n",
        "        for feat in feats_str.split('|'):\n",
        "            if '=' in feat:\n",
        "                key, value = feat.split('=', 1)\n",
        "                feats[key] = value\n",
        "    return feats\n",
        "\n",
        "def parse_conllu(filepath, max_sent=None):\n",
        "    sentences = []\n",
        "    current_tokens = []\n",
        "    sent_id = ''\n",
        "    text = ''\n",
        "\n",
        "    with open(filepath, 'r', encoding='utf-8') as f:\n",
        "        for line in f:\n",
        "            line = line.strip()\n",
        "            if line.startswith('# sent_id'):\n",
        "                sent_id = line.split('=', 1)[1].strip() if '=' in line else ''\n",
        "            elif line.startswith('# text'):\n",
        "                text = line.split('=', 1)[1].strip() if '=' in line else ''\n",
        "            elif line == '':\n",
        "                if current_tokens:\n",
        "                    sentences.append(Sentence(sent_id, text, current_tokens))\n",
        "                    current_tokens = []\n",
        "                    sent_id = ''\n",
        "                    text = ''\n",
        "                    if max_sent and len(sentences) >= max_sent:\n",
        "                        break\n",
        "            else:\n",
        "                fields = line.split('\\t')\n",
        "                if len(fields) == 10 and '-' not in fields[0] and '.' not in fields[0]:\n",
        "                    token = Token(\n",
        "                        id=int(fields[0]), form=fields[1], lemma=fields[2],\n",
        "                        upos=fields[3], xpos=fields[4], feats=parse_feats(fields[5]),\n",
        "                        head=int(fields[6]) if fields[6] != '_' else 0,\n",
        "                        deprel=fields[7], deps=fields[8], misc=fields[9]\n",
        "                    )\n",
        "                    current_tokens.append(token)\n",
        "\n",
        "    if current_tokens:\n",
        "        sentences.append(Sentence(sent_id, text, current_tokens))\n",
        "    return sentences\n",
        "\n",
        "# Create test file\n",
        "sample = '''# sent_id = 1\n",
        "# text = राम खाता है\n",
        "1\\tराम\\tराम\\tPROPN\\tNNP\\tCase=Nom\\t2\\tnsubj\\t_\\t_\n",
        "2\\tखाता\\tखा\\tVERB\\tVM\\t_\\t0\\troot\\t_\\t_\n",
        "3\\tहै\\tहै\\tAUX\\tVAUX\\t_\\t2\\taux\\t_\\t_\n",
        "'''\n",
        "with open('/tmp/test.conllu', 'w') as f:\n",
        "    f.write(sample)\n",
        "\n",
        "sents = parse_conllu('/tmp/test.conllu')\n",
        "print(f'Parsed {len(sents)} sentence(s)')\n",
        "print(f'Text: {sents[0].text}')\n",
        "print(f'Words: {sents[0].get_word_sequence()}')\n",
        "print('Test 2 passed!')"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parsed 1 sentence(s)\n",
            "Text: राम खाता है\n",
            "Words: ['राम', 'खाता', 'है']\n",
            "Test 2 passed!\n"
          ]
        }
      ],
      "id": "lBGJfOcN8AaY"
    },
    {
      "cell_type": "code",
      "source": [
        "# TEST 2B: CoNLL-U parsing with `conllu` library\n",
        "\n",
        "import sys\n",
        "import subprocess\n",
        "\n",
        "try:\n",
        "    from conllu import parse_incr\n",
        "except ImportError:\n",
        "    subprocess.check_call([sys.executable, '-m', 'pip', 'install', 'conllu'])\n",
        "    from conllu import parse_incr\n",
        "\n",
        "with open('/tmp/test.conllu', 'r', encoding='utf-8') as f:\n",
        "    parsed = list(parse_incr(f))\n",
        "\n",
        "print(f'Parsed {len(parsed)} sentence(s) with conllu library')\n",
        "print(f\"Text: {parsed[0].metadata.get('text', '')}\")\n",
        "print(f\"Words: {[tok['form'] for tok in parsed[0]]}\")\n",
        "print('Test 2B passed!')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hBCNDckrGPr6",
        "outputId": "c23324e7-c4c3-43cb-9e12-e4156c77060c"
      },
      "id": "hBCNDckrGPr6",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parsed 1 sentence(s) with conllu library\n",
            "Text: राम खाता है\n",
            "Words: ['राम', 'खाता', 'है']\n",
            "Test 2B passed!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "91RbZeFH8AaZ",
        "outputId": "28e39ddc-cc1d-4e0e-81e9-fb47beed1be9"
      },
      "source": [
        "# TEST 3: Trigram Model\n",
        "\n",
        "unigram_counts = Counter()\n",
        "bigram_counts = Counter()\n",
        "trigram_counts = Counter()\n",
        "vocab = set()\n",
        "total_tokens = 0\n",
        "\n",
        "train = [['राम', 'खाता', 'है'], ['सीता', 'खाती', 'है'], ['राम', 'सोता', 'है']]\n",
        "\n",
        "for sent in train:\n",
        "    toks = ['<s>', '<s>'] + sent + ['</s>']\n",
        "    for i in range(len(toks)):\n",
        "        unigram_counts[toks[i]] += 1\n",
        "        vocab.add(toks[i])\n",
        "        if i > 0:\n",
        "            bigram_counts[(toks[i-1], toks[i])] += 1\n",
        "        if i > 1:\n",
        "            trigram_counts[(toks[i-2], toks[i-1], toks[i])] += 1\n",
        "    total_tokens += len(sent)\n",
        "\n",
        "vocab_size = len(vocab)\n",
        "\n",
        "def get_prob(word, prev1, prev2):\n",
        "    l3, l2, l1 = 0.6, 0.3, 0.1\n",
        "    tc = trigram_counts.get((prev2, prev1, word), 0)\n",
        "    bc = bigram_counts.get((prev2, prev1), 0)\n",
        "    p3 = tc / bc if bc > 0 else 0\n",
        "    p2 = bigram_counts.get((prev1, word), 0) / unigram_counts.get(prev1, 1)\n",
        "    p1 = (unigram_counts.get(word, 0) + 1) / (total_tokens + vocab_size)\n",
        "    return max(l3*p3 + l2*p2 + l1*p1, 1e-10)\n",
        "\n",
        "def compute_surprisal(word_seq):\n",
        "    toks = ['<s>', '<s>'] + word_seq + ['</s>']\n",
        "    return [-math.log2(get_prob(toks[i], toks[i-1], toks[i-2])) for i in range(2, len(toks))]\n",
        "\n",
        "s = compute_surprisal(['राम', 'खाता', 'है'])\n",
        "print(f'Surprisal: {[round(x, 2) for x in s]}')\n",
        "print(f'Total: {round(sum(s), 2)} bits')\n",
        "print('Test 3 passed!')"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Surprisal: [0.95, 1.11, 0.11, 0.11]\n",
            "Total: 2.29 bits\n",
            "Test 3 passed!\n"
          ]
        }
      ],
      "id": "91RbZeFH8AaZ"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XJ3XjPNq8Aab",
        "outputId": "c5399542-fce3-4ee4-9ce1-01a9b95db6db"
      },
      "source": [
        "# TEST 4: UID Measures\n",
        "\n",
        "def mean_info(info_list):\n",
        "    return sum(info_list) / len(info_list) if info_list else 0\n",
        "\n",
        "def uid_global(info_list):\n",
        "    if len(info_list) <= 1:\n",
        "        return 0\n",
        "    m = mean_info(info_list)\n",
        "    return -sum((x - m)**2 for x in info_list) / len(info_list)\n",
        "\n",
        "def uid_local(info_list):\n",
        "    if len(info_list) <= 1:\n",
        "        return 0\n",
        "    diffs = [(info_list[i] - info_list[i-1])**2 for i in range(1, len(info_list))]\n",
        "    return -sum(diffs) / len(info_list)\n",
        "\n",
        "def uid_global_norm(info_list):\n",
        "    if len(info_list) <= 1:\n",
        "        return 0\n",
        "    m = mean_info(info_list)\n",
        "    if m == 0:\n",
        "        return 0\n",
        "    return -sum(((x/m) - 1)**2 for x in info_list) / len(info_list)\n",
        "\n",
        "def uid_local_norm(info_list):\n",
        "    if len(info_list) <= 1:\n",
        "        return 0\n",
        "    m = mean_info(info_list)\n",
        "    if m == 0:\n",
        "        return 0\n",
        "    diffs = [((info_list[i] - info_list[i-1])**2)/(m**2) for i in range(1, len(info_list))]\n",
        "    return -sum(diffs) / len(info_list)\n",
        "\n",
        "def uid_local_prev_norm(info_list):\n",
        "    if len(info_list) <= 1:\n",
        "        return 0\n",
        "    diffs = []\n",
        "    for i in range(1, len(info_list)):\n",
        "        if info_list[i-1] != 0:\n",
        "            diffs.append(((info_list[i]/info_list[i-1]) - 1)**2)\n",
        "    return -sum(diffs)/len(info_list) if diffs else 0\n",
        "\n",
        "info = [2.5, 3.0, 2.8, 3.2, 2.9]\n",
        "print(f'Info: {info}')\n",
        "print(f'UIDglob: {round(uid_global(info), 4)}')\n",
        "print(f'UIDloc: {round(uid_local(info), 4)}')\n",
        "print(f'UIDglobNorm: {round(uid_global_norm(info), 4)}')\n",
        "print(f'UIDlocNorm: {round(uid_local_norm(info), 4)}')\n",
        "print(f'UIDlocPrevNorm: {round(uid_local_prev_norm(info), 4)}')\n",
        "print('Test 4 passed!')"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Info: [2.5, 3.0, 2.8, 3.2, 2.9]\n",
            "UIDglob: -0.0536\n",
            "UIDloc: -0.108\n",
            "UIDglobNorm: -0.0065\n",
            "UIDlocNorm: -0.013\n",
            "UIDlocPrevNorm: -0.0147\n",
            "Test 4 passed!\n"
          ]
        }
      ],
      "id": "XJ3XjPNq8Aab"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CjQcFZSc8Aac",
        "outputId": "853e33ef-b213-4d6c-d233-e293e16e263c"
      },
      "source": [
        "# TEST 5: Variant Generator\n",
        "\n",
        "def get_preverbal_constituents(sent):\n",
        "    root = sent.get_root()\n",
        "    if not root:\n",
        "        return []\n",
        "    preverbal = [t for t in sent.tokens if t.id < root.id]\n",
        "    constituents = defaultdict(list)\n",
        "    for t in preverbal:\n",
        "        constituents[t.head].append(t)\n",
        "    result = []\n",
        "    for head_id in sorted(constituents.keys()):\n",
        "        result.append(sorted(constituents[head_id], key=lambda x: x.id))\n",
        "    return result\n",
        "\n",
        "def generate_variant(sent, perm):\n",
        "    consts = get_preverbal_constituents(sent)\n",
        "    root = sent.get_root()\n",
        "    post = [t for t in sent.tokens if root and t.id > root.id]\n",
        "    new_toks, nid = [], 1\n",
        "    for ci in perm:\n",
        "        if ci < len(consts):\n",
        "            for t in consts[ci]:\n",
        "                new_toks.append(Token(nid, t.form, t.lemma, t.upos, t.xpos, t.feats, 0, t.deprel, t.deps, t.misc))\n",
        "                nid += 1\n",
        "    if root:\n",
        "        new_toks.append(Token(nid, root.form, root.lemma, root.upos, root.xpos, root.feats, 0, root.deprel, root.deps, root.misc))\n",
        "        nid += 1\n",
        "    for t in post:\n",
        "        new_toks.append(Token(nid, t.form, t.lemma, t.upos, t.xpos, t.feats, t.head, t.deprel, t.deps, t.misc))\n",
        "        nid += 1\n",
        "    return Sentence(f\"{sent.sent_id}_var\", ' '.join([t.form for t in new_toks]), new_toks)\n",
        "\n",
        "def generate_variants(sent, max_var=99):\n",
        "    consts = get_preverbal_constituents(sent)\n",
        "    if len(consts) <= 1:\n",
        "        return []\n",
        "    perms = [p for p in permutations(range(len(consts))) if p != tuple(range(len(consts)))]\n",
        "    if len(perms) > max_var:\n",
        "        random.shuffle(perms)\n",
        "        perms = perms[:max_var]\n",
        "    return [generate_variant(sent, p) for p in perms]\n",
        "\n",
        "t1 = Token(1, 'राम', 'राम', 'PROPN', 'NNP', {}, 4, 'nsubj', '_', '_')\n",
        "t2 = Token(2, 'सेब', 'सेब', 'NOUN', 'NN', {}, 4, 'obj', '_', '_')\n",
        "t3 = Token(3, 'खाता', 'खा', 'VERB', 'VM', {}, 0, 'root', '_', '_')\n",
        "sent = Sentence('s1', 'राम सेब खाता है', [t1, t2, t3])\n",
        "\n",
        "vars = generate_variants(sent, 5)\n",
        "print(f'Original: {sent.text}')\n",
        "print(f'Generated {len(vars)} variants:')\n",
        "for v in vars:\n",
        "    print(f'  {v.text}')\n",
        "print('Test 5 passed!')"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original: राम सेब खाता है\n",
            "Generated 0 variants:\n",
            "Test 5 passed!\n"
          ]
        }
      ],
      "id": "CjQcFZSc8Aac"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2-JxCNln8Aae",
        "outputId": "230b1f0e-36cb-4b89-ff44-eba52922dc3b"
      },
      "source": [
        "# TEST 6: Pairwise Classifier\n",
        "\n",
        "def make_diff(f1, f2):\n",
        "    return [f2[k] - f1[k] for k in sorted(f1.keys())]\n",
        "\n",
        "def create_pairs(corp, var):\n",
        "    X, y = [], []\n",
        "    for c, v in zip(corp, var):\n",
        "        X.append(make_diff(c, v))\n",
        "        y.append(0)\n",
        "    for c, v in zip(corp, var):\n",
        "        X.append(make_diff(v, c))\n",
        "        y.append(1)\n",
        "    return np.array(X), np.array(y)\n",
        "\n",
        "corp = [{'s': 10, 'u': -5}, {'s': 12, 'u': -6}]\n",
        "var = [{'s': 15, 'u': -3}, {'s': 18, 'u': -2}]\n",
        "\n",
        "X, y = create_pairs(corp, var)\n",
        "clf = LogisticRegression(solver='lbfgs', max_iter=100)\n",
        "clf.fit(X, y)\n",
        "acc = clf.score(X, y)\n",
        "print(f'Accuracy: {acc*100:.1f}%')\n",
        "print('Test 6 passed!')"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 100.0%\n",
            "Test 6 passed!\n"
          ]
        }
      ],
      "id": "2-JxCNln8Aae"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lTryURTP8Aaf",
        "outputId": "de8c9dd4-563b-4ffe-f74d-d5f61f0bdeff"
      },
      "source": [
        "# TEST 7: Cross Validation\n",
        "\n",
        "def cross_val(X, y, n_folds=5):\n",
        "    kf = KFold(n_splits=n_folds, shuffle=True, random_state=42)\n",
        "    accs = []\n",
        "    for tr, te in kf.split(X):\n",
        "        clf = LogisticRegression(solver='lbfgs', max_iter=100)\n",
        "        clf.fit(X[tr], y[tr])\n",
        "        accs.append(clf.score(X[te], y[te]))\n",
        "    return np.mean(accs)\n",
        "\n",
        "X = np.random.randn(20, 3)\n",
        "y = np.random.randint(0, 2, 20)\n",
        "acc = cross_val(X, y, 5)\n",
        "print(f'CV Accuracy: {acc*100:.1f}%')\n",
        "print('Test 7 passed!')"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CV Accuracy: 55.0%\n",
            "Test 7 passed!\n"
          ]
        }
      ],
      "id": "lTryURTP8Aaf"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AjiwTQFY8Aag",
        "outputId": "0e573403-3b92-4ab2-ec4c-35b1e84b02c3"
      },
      "source": [
        "# TEST 8: Correlation\n",
        "\n",
        "def corr(x, y):\n",
        "    cx = [xi for xi, yi in zip(x, y) if not (np.isnan(xi) or np.isnan(yi))]\n",
        "    cy = [yi for xi, yi in zip(x, y) if not (np.isnan(xi) or np.isnan(yi))]\n",
        "    if len(cx) < 2:\n",
        "        return 0\n",
        "    return stats.pearsonr(cx, cy)[0]\n",
        "\n",
        "x = [1, 2, 3, 4, 5]\n",
        "y = [2, 4, 6, 8, 10]\n",
        "print(f'Correlation: {corr(x, y):.4f}')\n",
        "print('Test 8 passed!')\n",
        "\n",
        "print('\\n=== ALL TESTS PASSED ===')"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Correlation: 1.0000\n",
            "Test 8 passed!\n",
            "\n",
            "=== ALL TESTS PASSED ===\n"
          ]
        }
      ],
      "id": "AjiwTQFY8Aag"
    }
  ]
}